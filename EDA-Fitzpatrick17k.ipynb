{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b4500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Install kagglehub if you haven't:\n",
    "#    pip install kagglehub --upgrade\n",
    "import os, shutil, zipfile, pandas as pd, kagglehub\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ab549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏬  Downloading via kagglehub …\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "KaggleHub cache folder: C:\\Users\\yrsee\\.cache\\kagglehub\\datasets\\vinitasilaparasetty\\fitzpatrick-classification-by-ethnicity\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "KAGGLE_SLUG = \"vinitasilaparasetty/fitzpatrick-classification-by-ethnicity\"\n",
    "DEST        = Path(\"fitzpatrick17k\")          # final clean layout\n",
    "DEST.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ── 2. Download (kagglehub auto-caches) ───────────────────────────────────\n",
    "print(\"⏬  Downloading via kagglehub …\")\n",
    "dl_path = Path(\n",
    "    kagglehub.dataset_download(KAGGLE_SLUG)   # returns cache path\n",
    ")\n",
    "print(\"KaggleHub cache folder:\", dl_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0def9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 2. If a ZIP exists, unzip; else use the folder as-is ──────────────────\n",
    "zip_candidates = list(dl_path.glob(\"*.zip\"))\n",
    "if zip_candidates:\n",
    "    zip_file = zip_candidates[0]\n",
    "    print(\"📦  Extracting\", zip_file.name)\n",
    "    with zipfile.ZipFile(zip_file) as zf:\n",
    "        zf.extractall(DEST)\n",
    "else:\n",
    "    # The dataset is already extracted → copy contents to DEST\n",
    "    for item in dl_path.iterdir():\n",
    "        tgt = DEST / item.name\n",
    "        if tgt.exists():\n",
    "            continue\n",
    "        print(\"📁  Copying\", item.name, \"→\", tgt)\n",
    "        if item.is_dir():\n",
    "            shutil.copytree(item, tgt)\n",
    "        else:\n",
    "            shutil.copy2(item, tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebde2a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Dataset ready in: C:\\Users\\yrsee\\everything\\ACME-Outreach\\skin-diagnostic-engine\\fitzpatrick17k\n",
      "   ├─ fitzpatrick17k\\labels.csv\n",
      "   └─ fitzpatrick17k\\images\n"
     ]
    }
   ],
   "source": [
    "# ── 3. Standardize layout: move CSV + images/ ─────────────────────────────\n",
    "# Find the main CSV\n",
    "csv_path = next(DEST.rglob(\"*.csv\"))\n",
    "# Find the images folder (contains jpg / png)\n",
    "img_dir  = next(p for p in DEST.rglob(\"*\") if p.is_dir() and any(p.glob(\"*.jpg\")))\n",
    "\n",
    "if img_dir.resolve() != (DEST / \"images\").resolve():\n",
    "    shutil.move(str(img_dir), DEST / \"images\")\n",
    "\n",
    "print(f\"✅  Dataset ready in: {DEST.resolve()}\")\n",
    "print(\"   ├─\", (DEST / 'labels.csv').relative_to(DEST.parent))\n",
    "print(\"   └─\", (DEST / 'images').relative_to(DEST.parent))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a9b829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitzpatrick I–VI distribution:\n",
      " phototype\n",
      "I & II    903\n",
      "III       903\n",
      "IV        903\n",
      "V         903\n",
      "VI        903\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ── 4. Quick sanity: view distribution ────────────────────────────────────\n",
    "df = pd.read_csv(DEST / \"labels.csv\")\n",
    "dist = df[\"phototype\"].value_counts().sort_index()\n",
    "print(\"\\nFitzpatrick I–VI distribution:\\n\", dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df273d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# If you already have these, you can skip the installs.\n",
    "# Recommended CUDA 12.1 wheels for RTX 40xx:\n",
    "# !pip -q install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip -q install pandas scikit-learn matplotlib Pillow tqdm\n",
    "\n",
    "import sys, torch\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f75c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV columns: ['file', 'age', 'gender', 'race', 'phototype']\n",
      "        file    age  gender             race phototype\n",
      "0    100.jpg  20-29  Female       East Asian       III\n",
      "1   1000.jpg  20-29    Male  Latino_Hispanic        IV\n",
      "2  10000.jpg  20-29  Female       East Asian       III\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Point these at your prepared dataset\n",
    "DATA_ROOT = Path(\"fitzpatrick17k\")      # folder you created earlier\n",
    "CSV_PATH  = DATA_ROOT / \"labels.csv\"    # should exist\n",
    "IMG_ROOT  = DATA_ROOT / \"images\"        # should exist\n",
    "\n",
    "assert CSV_PATH.is_file(), f\"Missing CSV at {CSV_PATH}\"\n",
    "assert IMG_ROOT.is_dir(),  f\"Missing images/ at {IMG_ROOT}\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"CSV columns:\", df.columns.tolist())\n",
    "print(df.head(3))\n",
    "\n",
    "# Heuristic to find the image-path column if it isn't named 'image_path'\n",
    "for col in [\"image_path\",\"image\",\"filepath\",\"file\",\"filename\",\"path\"]:\n",
    "    if col in df.columns:\n",
    "        PATH_COL = col\n",
    "        break\n",
    "else:\n",
    "    raise KeyError(\"No image-path column found. Expected one of: image_path,image,filepath,file,filename,path\")\n",
    "\n",
    "LABEL_COL = \"phototype\"  # from your dataset\n",
    "assert LABEL_COL in df.columns, f\"'{LABEL_COL}' not found in CSV\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a735fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitzpatrick I–VI counts:\n",
      " phototype\n",
      "I & II    903\n",
      "III       903\n",
      "IV        903\n",
      "V         903\n",
      "VI        903\n"
     ]
    }
   ],
   "source": [
    "PLOT = False  # set True if you want a bar chart\n",
    "\n",
    "dist = df[LABEL_COL].value_counts().sort_index()\n",
    "print(\"Fitzpatrick I–VI counts:\\n\", dist.to_string())\n",
    "\n",
    "if PLOT:\n",
    "    import matplotlib.pyplot as plt\n",
    "    dist.plot(kind=\"bar\", title=\"Fitzpatrick I–VI distribution\")\n",
    "    plt.xlabel(\"Fitzpatrick type\"); plt.ylabel(\"# images\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556380b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0 — reset kernel (optional) and seed\n",
    "# Uncomment the reset line if you want a full kernel reset\n",
    "# %reset -f\n",
    "\n",
    "SEED = 42\n",
    "import random, os\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)  # for multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3da4610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df shape: (4515, 5)\n",
      "Columns: ['file', 'age', 'gender', 'race', 'phototype']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "phototype",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "17dc1f26-325b-4328-87eb-1b154eda45b2",
       "rows": [
        [
         "0",
         "100.jpg",
         "20-29",
         "Female",
         "East Asian",
         "III"
        ],
        [
         "1",
         "1000.jpg",
         "20-29",
         "Male",
         "Latino_Hispanic",
         "IV"
        ],
        [
         "2",
         "10000.jpg",
         "20-29",
         "Female",
         "East Asian",
         "III"
        ],
        [
         "3",
         "10001.jpg",
         "20-29",
         "Female",
         "Southeast Asian",
         "V"
        ],
        [
         "4",
         "10004.jpg",
         "20-29",
         "Male",
         "Southeast Asian",
         "V"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>phototype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file    age  gender             race phototype\n",
       "0    100.jpg  20-29  Female       East Asian       III\n",
       "1   1000.jpg  20-29    Male  Latino_Hispanic        IV\n",
       "2  10000.jpg  20-29  Female       East Asian       III\n",
       "3  10001.jpg  20-29  Female  Southeast Asian         V\n",
       "4  10004.jpg  20-29    Male  Southeast Asian         V"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata, urllib.parse, difflib\n",
    "from collections import Counter, defaultdict\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "DATA_ROOT = Path(\"fitzpatrick17k\")\n",
    "CSV_PATH  = DATA_ROOT / \"labels.csv\"\n",
    "IMG_ROOT  = DATA_ROOT / \"images\"\n",
    "\n",
    "assert CSV_PATH.exists(), f\"CSV not found at {CSV_PATH}\"\n",
    "assert IMG_ROOT.exists(), f\"images folder not found at {IMG_ROOT}\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Loaded df shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3819e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved: 4515  |  Missing: 0\n",
      "After dropna shape: (4515, 6)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: resolve paths (CSV column 'file')\n",
    "PATH_COL_RAW = \"file\"\n",
    "assert PATH_COL_RAW in df.columns, f\"Expected column '{PATH_COL_RAW}' in CSV\"\n",
    "\n",
    "# build file index under IMG_ROOT (case-insensitive)\n",
    "name_map, stem_map, rel_map = {}, {}, {}\n",
    "for p in IMG_ROOT.rglob(\"*\"):\n",
    "    if p.is_file():\n",
    "        rel = p.relative_to(IMG_ROOT)\n",
    "        name = unicodedata.normalize(\"NFKC\", p.name).lower()\n",
    "        stem = unicodedata.normalize(\"NFKC\", p.stem).lower()\n",
    "        rel_s = str(rel).replace(\"\\\\\",\"/\").lower()\n",
    "        name_map[name] = rel\n",
    "        stem_map.setdefault(stem, []).append(rel)\n",
    "        rel_map[rel_s] = rel\n",
    "\n",
    "def _clean_input(raw):\n",
    "    if pd.isna(raw): return None\n",
    "    s = str(raw).strip()\n",
    "    if (s.startswith('\"') and s.endswith('\"')) or (s.startswith(\"'\") and s.endswith(\"'\")):\n",
    "        s = s[1:-1].strip()\n",
    "    parsed = urllib.parse.urlparse(s)\n",
    "    path = parsed.path if parsed.scheme else s\n",
    "    path = urllib.parse.unquote(path.split(\"?\")[0].split(\"#\")[0])\n",
    "    return unicodedata.normalize(\"NFKC\", path).replace(\"\\\\\",\"/\")\n",
    "\n",
    "def resolve_path(raw):\n",
    "    p = _clean_input(raw)\n",
    "    if not p: return None\n",
    "    base = Path(p).name.lower()\n",
    "    base = unicodedata.normalize(\"NFKC\", base)\n",
    "    if base in name_map: return str(name_map[base])\n",
    "    stem = Path(base).stem.lower()\n",
    "    if stem in stem_map and len(stem_map[stem])>0: return str(stem_map[stem][0])\n",
    "    rel_try = p.lower().lstrip(\"./\")\n",
    "    if rel_try in rel_map: return str(rel_map[rel_try])\n",
    "    tail = rel_try.split(\"/\")[-1]\n",
    "    for k,v in rel_map.items():\n",
    "        if k.endswith(\"/\"+tail) or k==tail: return str(v)\n",
    "    cand = difflib.get_close_matches(base, list(name_map.keys()), n=1, cutoff=0.85)\n",
    "    if cand: return str(name_map[cand[0]])\n",
    "    return None\n",
    "\n",
    "df[\"resolved_path\"] = df[PATH_COL_RAW].apply(resolve_path)\n",
    "missing = df[\"resolved_path\"].isna().sum()\n",
    "print(f\"Resolved: {len(df)-missing}  |  Missing: {missing}\")\n",
    "if missing:\n",
    "    display(df.loc[df[\"resolved_path\"].isna(), [PATH_COL_RAW]].head(10))\n",
    "# drop rows without image file\n",
    "df = df.dropna(subset=[\"resolved_path\"]).reset_index(drop=True)\n",
    "print(\"After dropna shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a58e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label source: phototype\n",
      "3-class distribution (0=light,1=medium,2=dark):\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — map original Fitzpatrick labels to 3 classes\n",
    "# Try common label column names\n",
    "possible_label_cols = [c for c in [\"fitzpatrick\", \"phototype\", \"label\", \"class\", \"_label_idx\", \"target\"] if c in df.columns]\n",
    "LABEL_COL = possible_label_cols[0] if possible_label_cols else None\n",
    "if LABEL_COL is None:\n",
    "    raise KeyError(\"No label-like column found in CSV. Columns: \" + \", \".join(df.columns))\n",
    "print(\"Using label source:\", LABEL_COL)\n",
    "\n",
    "# coerce to numeric where possible\n",
    "df[LABEL_COL] = pd.to_numeric(df[LABEL_COL], errors=\"coerce\")\n",
    "# drop rows without numeric label\n",
    "df = df.dropna(subset=[LABEL_COL]).reset_index(drop=True)\n",
    "\n",
    "# Map Fitzpatrick numeric values -> 3 classes\n",
    "# If values are 1..6 -> map 1,2->0 light; 3,4->1 medium; 5,6->2 dark\n",
    "def fitz_to_3(x):\n",
    "    x = int(x)\n",
    "    if x <= 2:\n",
    "        return 0\n",
    "    elif x <= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df[\"label3\"] = df[LABEL_COL].apply(fitz_to_3)\n",
    "print(\"3-class distribution (0=light,1=medium,2=dark):\")\n",
    "print(df[\"label3\"].value_counts().sort_index())\n",
    "num_classes = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e0a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-class distribution: {}\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: map phototype -> 3 classes (0 light, 1 medium, 2 dark)\n",
    "def roman_to_int_safe(x):\n",
    "    if pd.isna(x): return None\n",
    "    s = str(x).strip().upper()\n",
    "    # simple roman map for I..VI, also handles '3' etc.\n",
    "    roman_map = {\"I\":1,\"II\":2,\"III\":3,\"IV\":4,\"V\":5,\"VI\":6}\n",
    "    if s in roman_map: return roman_map[s]\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        # try first character numeric in strings like \"III\\n\"\n",
    "        for token in s.split():\n",
    "            try:\n",
    "                return int(token)\n",
    "            except: pass\n",
    "    return None\n",
    "\n",
    "df[\"phototype_num\"] = df[\"phototype\"].apply(roman_to_int_safe)\n",
    "n_missing = df[\"phototype_num\"].isna().sum()\n",
    "if n_missing:\n",
    "    print(\"Rows with missing/unparsable phototype:\", n_missing)\n",
    "    display(df.loc[df[\"phototype_num\"].isna(), [\"phototype\",\"resolved_path\"]].head(10))\n",
    "    df = df.dropna(subset=[\"phototype_num\"]).reset_index(drop=True)\n",
    "\n",
    "def map3(x):\n",
    "    x = int(x)\n",
    "    if x <= 2: return 0   # I-II -> light\n",
    "    if x <= 4: return 1   # III-IV -> medium\n",
    "    return 2              # V-VI -> dark\n",
    "\n",
    "df[\"label3\"] = df[\"phototype_num\"].apply(map3)\n",
    "print(\"3-class distribution:\", df[\"label3\"].value_counts().sort_index().to_dict())\n",
    "num_classes = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "933c9181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflicting files count: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: check conflicts (same resolved_path -> multiple label3)\n",
    "dupes = df.groupby(\"resolved_path\").agg(n_rows=(\"resolved_path\",\"size\"), n_labels=(\"label3\",\"nunique\"))\n",
    "conflicts = dupes[dupes[\"n_labels\"]>1]\n",
    "print(\"Conflicting files count:\", len(conflicts))\n",
    "if len(conflicts)>0:\n",
    "    display(conflicts.head(10))\n",
    "    print(\"Example conflicts (path -> labels):\")\n",
    "    for p in conflicts.index[:10]:\n",
    "        print(p, \"->\", sorted(df.loc[df[\"resolved_path\"]==p, \"label3\"].unique().tolist()))\n",
    "\n",
    "# Option (manual): if few, you can drop conflicts or choose majority label.\n",
    "# Automated majority-dedupe (uncomment to enable):\n",
    "# from collections import Counter\n",
    "# if len(conflicts)>0:\n",
    "#     keep=[]\n",
    "#     for p,g in df.groupby(\"resolved_path\"):\n",
    "#         if g[\"label3\"].nunique()==1:\n",
    "#             keep.append(g.iloc[0])\n",
    "#         else:\n",
    "#             maj = Counter(g[\"label3\"]).most_common(1)[0][0]\n",
    "#             keep.append(g[g[\"label3\"]==maj].iloc[0])\n",
    "#     df = pd.DataFrame(keep).reset_index(drop=True)\n",
    "#     print(\"After majority dedupe:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85bc9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 0 val len: 0\n",
      "train distribution: Counter()\n",
      "val distribution: Counter()\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: stratified train/val split without sklearn\n",
    "from collections import defaultdict\n",
    "np.random.seed(42)\n",
    "indices_by_class = defaultdict(list)\n",
    "for idx, lbl in enumerate(df[\"label3\"].values):\n",
    "    indices_by_class[int(lbl)].append(idx)\n",
    "\n",
    "train_idx, val_idx = [], []\n",
    "frac_train = 0.8\n",
    "for lbl, idxs in indices_by_class.items():\n",
    "    idxs = idxs.copy()\n",
    "    np.random.shuffle(idxs)\n",
    "    split = int(len(idxs)*frac_train)\n",
    "    train_idx += idxs[:split]\n",
    "    val_idx += idxs[split:]\n",
    "\n",
    "train_idx = sorted(set(train_idx))\n",
    "val_idx = sorted(set(val_idx))\n",
    "print(\"train len:\", len(train_idx), \"val len:\", len(val_idx))\n",
    "print(\"train distribution:\", Counter(df.loc[train_idx,\"label3\"]))\n",
    "print(\"val distribution:\", Counter(df.loc[val_idx,\"label3\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79091e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         lbl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_col])\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img, torch\u001b[38;5;241m.\u001b[39mtensor(lbl, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m---> 28\u001b[0m train_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mtrain_idx\u001b[49m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m val_df   \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[val_idx]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m Melanin3Dataset(train_df, IMG_ROOT, tf\u001b[38;5;241m=\u001b[39mtrain_tf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_idx' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 6: dataset, transforms, balanced sampler\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "IMG_SIZE = 224\n",
    "train_tf = T.Compose([T.Resize((IMG_SIZE,IMG_SIZE)), T.RandomHorizontalFlip(),\n",
    "                      T.ColorJitter(0.2,0.2,0.2,0.02), T.ToTensor(),\n",
    "                      T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "val_tf = T.Compose([T.Resize((IMG_SIZE,IMG_SIZE)), T.ToTensor(),\n",
    "                    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "\n",
    "class Melanin3Dataset(Dataset):\n",
    "    def __init__(self, df_subset, img_root, path_col=\"resolved_path\", label_col=\"label3\", tf=None):\n",
    "        self.df = df_subset.reset_index(drop=True)\n",
    "        self.img_root = Path(img_root)\n",
    "        self.path_col = path_col\n",
    "        self.label_col = label_col\n",
    "        self.tf = tf\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        p = self.img_root / row[self.path_col]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.tf: img = self.tf(img)\n",
    "        lbl = int(row[self.label_col])\n",
    "        return img, torch.tensor(lbl, dtype=torch.long)\n",
    "\n",
    "train_df = df.loc[train_idx].reset_index(drop=True)\n",
    "val_df   = df.loc[val_idx].reset_index(drop=True)\n",
    "train_ds = Melanin3Dataset(train_df, IMG_ROOT, tf=train_tf)\n",
    "val_ds   = Melanin3Dataset(val_df, IMG_ROOT, tf=val_tf)\n",
    "\n",
    "# balanced sampler (manual)\n",
    "labels = train_df[\"label3\"].astype(int).values\n",
    "classes, counts = np.unique(labels, return_counts=True)\n",
    "total = labels.shape[0]\n",
    "class_weights = {int(c): float(total / (len(classes) * cnt)) for c,cnt in zip(classes, counts)}\n",
    "samples_weight = np.array([class_weights[int(l)] for l in labels], dtype=np.float32)\n",
    "sampler = WeightedRandomSampler(weights=samples_weight, num_samples=len(samples_weight), replacement=True)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# quick sanity\n",
    "for imgs, labels in train_loader:\n",
    "    print(\"batch imgs\", imgs.shape, \"labels min/max\", labels.min().item(), labels.max().item())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd67004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV exists: True\n",
      "IMG_ROOT exists: True\n",
      "\n",
      "Reloaded df shape: (4515, 5)\n",
      "Columns: ['file', 'age', 'gender', 'race', 'phototype']\n",
      "\n",
      "Sample rows (first 10):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "phototype",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b16651df-50e2-44ed-827f-f29807c20a64",
       "rows": [
        [
         "0",
         "100.jpg",
         "20-29",
         "Female",
         "East Asian",
         "III"
        ],
        [
         "1",
         "1000.jpg",
         "20-29",
         "Male",
         "Latino_Hispanic",
         "IV"
        ],
        [
         "2",
         "10000.jpg",
         "20-29",
         "Female",
         "East Asian",
         "III"
        ],
        [
         "3",
         "10001.jpg",
         "20-29",
         "Female",
         "Southeast Asian",
         "V"
        ],
        [
         "4",
         "10004.jpg",
         "20-29",
         "Male",
         "Southeast Asian",
         "V"
        ],
        [
         "5",
         "10005.jpg",
         "30-39",
         "Female",
         "Indian",
         "V"
        ],
        [
         "6",
         "10006.jpg",
         "40-49",
         "Male",
         "Black",
         "VI"
        ],
        [
         "7",
         "10007.jpg",
         "40-49",
         "Female",
         "Latino_Hispanic",
         "IV"
        ],
        [
         "8",
         "10008.jpg",
         "20-29",
         "Female",
         "East Asian",
         "III"
        ],
        [
         "9",
         "10009.jpg",
         "60-69",
         "Male",
         "White",
         "I & II"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>phototype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009.jpg</td>\n",
       "      <td>60-69</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>I &amp; II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file    age  gender             race phototype\n",
       "0    100.jpg  20-29  Female       East Asian       III\n",
       "1   1000.jpg  20-29    Male  Latino_Hispanic        IV\n",
       "2  10000.jpg  20-29  Female       East Asian       III\n",
       "3  10001.jpg  20-29  Female  Southeast Asian         V\n",
       "4  10004.jpg  20-29    Male  Southeast Asian         V\n",
       "5  10005.jpg  30-39  Female           Indian         V\n",
       "6  10006.jpg  40-49    Male            Black        VI\n",
       "7  10007.jpg  40-49  Female  Latino_Hispanic        IV\n",
       "8  10008.jpg  20-29  Female       East Asian       III\n",
       "9  10009.jpg  60-69    Male            White    I & II"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file unique / nulls: unique=4515, nulls=0\n",
      "phototype unique / nulls: unique=5, nulls=0\n",
      "phototype_num NOT in df\n",
      "resolved_path NOT in df\n",
      "label3 NOT in df\n"
     ]
    }
   ],
   "source": [
    "# Cell A: inspect df and the CSV-derived columns\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "DATA_ROOT = Path(\"fitzpatrick17k\")\n",
    "CSV_PATH  = DATA_ROOT / \"labels.csv\"\n",
    "IMG_ROOT  = DATA_ROOT / \"images\"\n",
    "\n",
    "print(\"CSV exists:\", CSV_PATH.exists())\n",
    "print(\"IMG_ROOT exists:\", IMG_ROOT.exists())\n",
    "print()\n",
    "\n",
    "# Try re-load the CSV (fresh) to ensure no stale state\n",
    "try:\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    print(\"Reloaded df shape:\", df.shape)\n",
    "except Exception as e:\n",
    "    print(\"Failed to reload CSV:\", repr(e))\n",
    "    raise\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nSample rows (first 10):\")\n",
    "display(df.head(10))\n",
    "\n",
    "# show unique counts for relevant columns if present\n",
    "for col in [\"file\",\"phototype\",\"phototype_num\",\"resolved_path\",\"label3\"]:\n",
    "    if col in df.columns:\n",
    "        print(f\"{col} unique / nulls: unique={df[col].nunique()}, nulls={df[col].isna().sum()}\")\n",
    "    else:\n",
    "        print(f\"{col} NOT in df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fddb00e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files under images/: 35447\n",
      "Example files (first 20):\n",
      "  1.jpg\n",
      "  10.jpg\n",
      "  100.jpg\n",
      "  1000.jpg\n",
      "  10004.jpg\n",
      "  10005.jpg\n",
      "  10006.jpg\n",
      "  10008.jpg\n",
      "  1001.jpg\n",
      "  10010.jpg\n",
      "  10013.jpg\n",
      "  10015.jpg\n",
      "  10016.jpg\n",
      "  10017.jpg\n",
      "  10018.jpg\n",
      "  10019.jpg\n",
      "  1002.jpg\n",
      "  10021.jpg\n",
      "  10024.jpg\n",
      "  10025.jpg\n",
      "\n",
      "CSV rows where basename matches a file on disk: 2331 / 4515\n",
      "Examples (file -> exists):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_basename_lc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exists_basename",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "b47bb86a-77b7-4efb-bf77-2fd195ddec3e",
       "rows": [
        [
         "0",
         "100.jpg",
         "100.jpg",
         "True"
        ],
        [
         "1",
         "1000.jpg",
         "1000.jpg",
         "True"
        ],
        [
         "2",
         "10000.jpg",
         "10000.jpg",
         "False"
        ],
        [
         "3",
         "10001.jpg",
         "10001.jpg",
         "False"
        ],
        [
         "4",
         "10004.jpg",
         "10004.jpg",
         "True"
        ],
        [
         "5",
         "10005.jpg",
         "10005.jpg",
         "True"
        ],
        [
         "6",
         "10006.jpg",
         "10006.jpg",
         "True"
        ],
        [
         "7",
         "10007.jpg",
         "10007.jpg",
         "False"
        ],
        [
         "8",
         "10008.jpg",
         "10008.jpg",
         "True"
        ],
        [
         "9",
         "10009.jpg",
         "10009.jpg",
         "False"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>file_basename_lc</th>\n",
       "      <th>exists_basename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>100.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001.jpg</td>\n",
       "      <td>10001.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007.jpg</td>\n",
       "      <td>10007.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009.jpg</td>\n",
       "      <td>10009.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file file_basename_lc  exists_basename\n",
       "0    100.jpg          100.jpg             True\n",
       "1   1000.jpg         1000.jpg             True\n",
       "2  10000.jpg        10000.jpg            False\n",
       "3  10001.jpg        10001.jpg            False\n",
       "4  10004.jpg        10004.jpg             True\n",
       "5  10005.jpg        10005.jpg             True\n",
       "6  10006.jpg        10006.jpg             True\n",
       "7  10007.jpg        10007.jpg            False\n",
       "8  10008.jpg        10008.jpg             True\n",
       "9  10009.jpg        10009.jpg            False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell B: list some actual image files on disk and build a name-index\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "IMG_ROOT = Path(\"fitzpatrick17k\") / \"images\"\n",
    "files = [p for p in IMG_ROOT.rglob(\"*\") if p.is_file()]\n",
    "print(\"Number of files under images/:\", len(files))\n",
    "print(\"Example files (first 20):\")\n",
    "for p in files[:20]:\n",
    "    print(\" \", p.relative_to(IMG_ROOT))\n",
    "\n",
    "# create a mapping of lowercase basename -> relative path\n",
    "name_map = {}\n",
    "for p in files:\n",
    "    name = unicodedata.normalize(\"NFKC\", p.name).lower()\n",
    "    name_map[name] = p.relative_to(IMG_ROOT)\n",
    "\n",
    "# check whether any CSV file entries directly match basenames\n",
    "if \"file\" in df.columns:\n",
    "    df[\"file_str\"] = df[\"file\"].astype(str).str.strip()\n",
    "    df[\"file_basename_lc\"] = df[\"file_str\"].apply(lambda s: str(s).split(\"/\")[-1].split(\"\\\\\")[-1].lower())\n",
    "    df[\"exists_basename\"] = df[\"file_basename_lc\"].apply(lambda b: b in name_map)\n",
    "    print(\"\\nCSV rows where basename matches a file on disk:\", df[\"exists_basename\"].sum(), \"/\", len(df))\n",
    "    print(\"Examples (file -> exists):\")\n",
    "    display(df.loc[df[\"exists_basename\"].head(10).index, [\"file\",\"file_basename_lc\",\"exists_basename\"]].head(10))\n",
    "else:\n",
    "    print(\"No 'file' column in CSV to check against filesystem.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9daac468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV rows: 4515\n",
      "CSV columns: ['file', 'age', 'gender', 'race', 'phototype']\n",
      "\n",
      "Number of files under images/: 35447\n",
      "Example files (first 20):\n",
      "  1.jpg\n",
      "  10.jpg\n",
      "  100.jpg\n",
      "  1000.jpg\n",
      "  10004.jpg\n",
      "  10005.jpg\n",
      "  10006.jpg\n",
      "  10008.jpg\n",
      "  1001.jpg\n",
      "  10010.jpg\n",
      "  10013.jpg\n",
      "  10015.jpg\n",
      "  10016.jpg\n",
      "  10017.jpg\n",
      "  10018.jpg\n",
      "  10019.jpg\n",
      "  1002.jpg\n",
      "  10021.jpg\n",
      "  10024.jpg\n",
      "  10025.jpg\n",
      "\n",
      "Basename matches found: 2331 / 4515 (51.6%)\n",
      "\n",
      "Sample (first 15) unmatched CSV file basenames:\n",
      "['10000.jpg', '10001.jpg', '10007.jpg', '10009.jpg', '10011.jpg', '10012.jpg', '10020.jpg', '10022.jpg', '10023.jpg', '10028.jpg', '10031.jpg', '10035.jpg', '10037.jpg', '10040.jpg', '10041.jpg']\n",
      "\n",
      "Phototype parseable: 4515 / 4515  (missing: 0)\n",
      "\n",
      "df_clean (have image + phototype): 2331 rows\n",
      "label3 distribution in df_clean: {0: np.int64(501), 1: np.int64(827), 2: np.int64(1003)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_basename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resolved_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "phototype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "phototype_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label3",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "bbffda51-bd3c-4d25-bb38-24f5de5586bc",
       "rows": [
        [
         "0",
         "100.jpg",
         "100.jpg",
         "100.jpg",
         "III",
         "3",
         "1"
        ],
        [
         "1",
         "1000.jpg",
         "1000.jpg",
         "1000.jpg",
         "IV",
         "4",
         "1"
        ],
        [
         "2",
         "10004.jpg",
         "10004.jpg",
         "10004.jpg",
         "V",
         "5",
         "2"
        ],
        [
         "3",
         "10005.jpg",
         "10005.jpg",
         "10005.jpg",
         "V",
         "5",
         "2"
        ],
        [
         "4",
         "10006.jpg",
         "10006.jpg",
         "10006.jpg",
         "VI",
         "6",
         "2"
        ],
        [
         "5",
         "10008.jpg",
         "10008.jpg",
         "10008.jpg",
         "III",
         "3",
         "1"
        ],
        [
         "6",
         "1001.jpg",
         "1001.jpg",
         "1001.jpg",
         "V",
         "5",
         "2"
        ],
        [
         "7",
         "10010.jpg",
         "10010.jpg",
         "10010.jpg",
         "V",
         "5",
         "2"
        ],
        [
         "8",
         "10013.jpg",
         "10013.jpg",
         "10013.jpg",
         "III",
         "3",
         "1"
        ],
        [
         "9",
         "10015.jpg",
         "10015.jpg",
         "10015.jpg",
         "III",
         "3",
         "1"
        ],
        [
         "10",
         "10016.jpg",
         "10016.jpg",
         "10016.jpg",
         "V",
         "5",
         "2"
        ],
        [
         "11",
         "10017.jpg",
         "10017.jpg",
         "10017.jpg",
         "VI",
         "6",
         "2"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>file_basename</th>\n",
       "      <th>resolved_path</th>\n",
       "      <th>phototype</th>\n",
       "      <th>phototype_num</th>\n",
       "      <th>label3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>100.jpg</td>\n",
       "      <td>100.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>IV</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>VI</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10017.jpg</td>\n",
       "      <td>10017.jpg</td>\n",
       "      <td>10017.jpg</td>\n",
       "      <td>VI</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file file_basename resolved_path phototype  phototype_num  label3\n",
       "0     100.jpg       100.jpg       100.jpg       III              3       1\n",
       "1    1000.jpg      1000.jpg      1000.jpg        IV              4       1\n",
       "2   10004.jpg     10004.jpg     10004.jpg         V              5       2\n",
       "3   10005.jpg     10005.jpg     10005.jpg         V              5       2\n",
       "4   10006.jpg     10006.jpg     10006.jpg        VI              6       2\n",
       "5   10008.jpg     10008.jpg     10008.jpg       III              3       1\n",
       "6    1001.jpg      1001.jpg      1001.jpg         V              5       2\n",
       "7   10010.jpg     10010.jpg     10010.jpg         V              5       2\n",
       "8   10013.jpg     10013.jpg     10013.jpg       III              3       1\n",
       "9   10015.jpg     10015.jpg     10015.jpg       III              3       1\n",
       "10  10016.jpg     10016.jpg     10016.jpg         V              5       2\n",
       "11  10017.jpg     10017.jpg     10017.jpg        VI              6       2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of basename duplicates on disk: 0\n",
      "\n",
      "Assigned df = df_clean; ready for next steps (split / dataset).\n"
     ]
    }
   ],
   "source": [
    "# Robust resolver + phototype parser diagnostic (run now)\n",
    "from pathlib import Path\n",
    "import unicodedata, re\n",
    "import pandas as pd, numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "DATA_ROOT = Path(\"fitzpatrick17k\")\n",
    "CSV_PATH  = DATA_ROOT / \"labels.csv\"\n",
    "IMG_ROOT  = DATA_ROOT / \"images\"\n",
    "\n",
    "# reload df fresh to avoid stale state\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"CSV rows:\", len(df))\n",
    "print(\"CSV columns:\", df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# 1) list files under images/\n",
    "files = [p for p in IMG_ROOT.rglob(\"*\") if p.is_file()]\n",
    "print(\"Number of files under images/:\", len(files))\n",
    "print(\"Example files (first 20):\")\n",
    "for p in files[:20]:\n",
    "    print(\" \", p.relative_to(IMG_ROOT))\n",
    "print()\n",
    "\n",
    "# 2) build basename -> relative path map (case-insensitive, unicode-normalized)\n",
    "name_map = {}\n",
    "for p in files:\n",
    "    name = unicodedata.normalize(\"NFKC\", p.name).lower()\n",
    "    # prefer first seen; if duplicates exist, we'll keep the first (we can surface duplicates later)\n",
    "    if name not in name_map:\n",
    "        name_map[name] = p.relative_to(IMG_ROOT)\n",
    "\n",
    "# 3) try to match CSV 'file' entries to actual files by basename\n",
    "if \"file\" not in df.columns:\n",
    "    raise KeyError(\"'file' column not found in CSV. Columns: \" + \", \".join(df.columns))\n",
    "\n",
    "def basename_only(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip()\n",
    "    # take basename only in case CSV includes path segments\n",
    "    s = s.split(\"/\")[-1].split(\"\\\\\")[-1]\n",
    "    return unicodedata.normalize(\"NFKC\", s).lower()\n",
    "\n",
    "df[\"file_basename\"] = df[\"file\"].apply(basename_only)\n",
    "df[\"match_basename\"] = df[\"file_basename\"].apply(lambda b: name_map.get(b, None))\n",
    "\n",
    "n_matched = df[\"match_basename\"].notna().sum()\n",
    "print(f\"Basename matches found: {n_matched} / {len(df)} ({n_matched/len(df):.1%})\")\n",
    "\n",
    "if n_matched < len(df):\n",
    "    print(\"\\nSample (first 15) unmatched CSV file basenames:\")\n",
    "    unmatched = df.loc[df[\"match_basename\"].isna(), \"file_basename\"].head(15).tolist()\n",
    "    print(unmatched)\n",
    "\n",
    "# 4) if some matched, assign resolved_path column\n",
    "df[\"resolved_path\"] = df[\"match_basename\"].apply(lambda r: str(r) if pd.notna(r) else None)\n",
    "\n",
    "# 5) parse phototype strings robustly into numeric 1..6\n",
    "def parse_phototype(s):\n",
    "    if pd.isna(s): return None\n",
    "    s = str(s).upper()\n",
    "    # look for roman numerals or digits I..VI or 1..6\n",
    "    # regex finds the first valid token like I, II, III, IV, V, VI, or digit 1-6\n",
    "    m = re.search(r'\\b(I{1,3}|IV|V|VI|[1-6])\\b', s)\n",
    "    if not m:\n",
    "        return None\n",
    "    token = m.group(1)\n",
    "    roman_map = {\"I\":1,\"II\":2,\"III\":3,\"IV\":4,\"V\":5,\"VI\":6}\n",
    "    if token in roman_map:\n",
    "        return roman_map[token]\n",
    "    try:\n",
    "        return int(token)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"phototype_num\"] = df[\"phototype\"].apply(parse_phototype)\n",
    "n_ph_missing = df[\"phototype_num\"].isna().sum()\n",
    "print(f\"\\nPhototype parseable: {len(df)-n_ph_missing} / {len(df)}  (missing: {n_ph_missing})\")\n",
    "if n_ph_missing>0:\n",
    "    display(df.loc[df[\"phototype_num\"].isna(), [\"phototype\",\"file\"]].head(10))\n",
    "\n",
    "# 6) create label3 (0=light I-II, 1=medium III-IV, 2=dark V-VI)\n",
    "def to_label3(x):\n",
    "    if x is None: return None\n",
    "    x = int(x)\n",
    "    if x <= 2: return 0\n",
    "    if x <= 4: return 1\n",
    "    return 2\n",
    "\n",
    "df[\"label3\"] = df[\"phototype_num\"].apply(lambda x: to_label3(x) if pd.notna(x) else None)\n",
    "\n",
    "# 7) keep only rows that have both resolved_path and label3\n",
    "df_clean = df.dropna(subset=[\"resolved_path\",\"label3\"]).reset_index(drop=True)\n",
    "print(f\"\\ndf_clean (have image + phototype): {len(df_clean)} rows\")\n",
    "print(\"label3 distribution in df_clean:\", dict(df_clean[\"label3\"].value_counts().sort_index()))\n",
    "print()\n",
    "\n",
    "# 8) If df_clean is non-empty, show a small sample with full details\n",
    "if len(df_clean) > 0:\n",
    "    display(df_clean[[\"file\",\"file_basename\",\"resolved_path\",\"phototype\",\"phototype_num\",\"label3\"]].head(12))\n",
    "else:\n",
    "    # detailed diagnostics when we failed to match anything\n",
    "    print(\"No rows with both matched image and parseable phototype.\")\n",
    "    print(\"Top 20 CSV 'file' basenames (for inspection):\")\n",
    "    print(df[\"file_basename\"].head(20).tolist())\n",
    "    print(\"\\nTop 40 image basenames on disk (for inspection):\")\n",
    "    print(list(name_map.keys())[:40])\n",
    "\n",
    "# 9) show duplicates on disk for basenames (optional info)\n",
    "from collections import defaultdict\n",
    "duplicates = defaultdict(list)\n",
    "for p in files:\n",
    "    b = unicodedata.normalize(\"NFKC\", p.name).lower()\n",
    "    duplicates[b].append(p.relative_to(IMG_ROOT))\n",
    "dups = {k:v for k,v in duplicates.items() if len(v)>1}\n",
    "print(\"\\nNumber of basename duplicates on disk:\", len(dups))\n",
    "if len(dups) > 0:\n",
    "    # show a couple examples\n",
    "    for k,v in list(dups.items())[:8]:\n",
    "        print(k, \"->\", v)\n",
    "\n",
    "# write df back to namespace for downstream work if non-empty\n",
    "if len(df_clean) > 0:\n",
    "    df = df_clean\n",
    "    print(\"\\nAssigned df = df_clean; ready for next steps (split / dataset).\")\n",
    "else:\n",
    "    print(\"\\ndf not replaced. Fix matching or phototype parsing before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d11c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_ROOT: fitzpatrick17k\\images exists: True\n",
      "Already matched (baseline): 2331 Unmatched: 0\n",
      "Auto matches found: 0\n",
      "Manual suggestion cases: 0\n",
      "Remaining fully unmatched: 0\n",
      "Matched by method counts:\n",
      " match_method\n",
      "exact    2331\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Examples of auto matches:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_basename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resolved_path_auto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "match_method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "match_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d6ad9a49-da01-49cb-9a9b-5e8506116c8c",
       "rows": [
        [
         "0",
         "100.jpg",
         "100.jpg",
         "100.jpg",
         "exact",
         null
        ],
        [
         "1",
         "1000.jpg",
         "1000.jpg",
         "1000.jpg",
         "exact",
         null
        ],
        [
         "2",
         "10004.jpg",
         "10004.jpg",
         "10004.jpg",
         "exact",
         null
        ],
        [
         "3",
         "10005.jpg",
         "10005.jpg",
         "10005.jpg",
         "exact",
         null
        ],
        [
         "4",
         "10006.jpg",
         "10006.jpg",
         "10006.jpg",
         "exact",
         null
        ],
        [
         "5",
         "10008.jpg",
         "10008.jpg",
         "10008.jpg",
         "exact",
         null
        ],
        [
         "6",
         "1001.jpg",
         "1001.jpg",
         "1001.jpg",
         "exact",
         null
        ],
        [
         "7",
         "10010.jpg",
         "10010.jpg",
         "10010.jpg",
         "exact",
         null
        ],
        [
         "8",
         "10013.jpg",
         "10013.jpg",
         "10013.jpg",
         "exact",
         null
        ],
        [
         "9",
         "10015.jpg",
         "10015.jpg",
         "10015.jpg",
         "exact",
         null
        ],
        [
         "10",
         "10016.jpg",
         "10016.jpg",
         "10016.jpg",
         "exact",
         null
        ],
        [
         "11",
         "10017.jpg",
         "10017.jpg",
         "10017.jpg",
         "exact",
         null
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>file_basename</th>\n",
       "      <th>resolved_path_auto</th>\n",
       "      <th>match_method</th>\n",
       "      <th>match_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>100.jpg</td>\n",
       "      <td>100.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10017.jpg</td>\n",
       "      <td>10017.jpg</td>\n",
       "      <td>10017.jpg</td>\n",
       "      <td>exact</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file file_basename resolved_path_auto match_method match_info\n",
       "0     100.jpg       100.jpg            100.jpg        exact       None\n",
       "1    1000.jpg      1000.jpg           1000.jpg        exact       None\n",
       "2   10004.jpg     10004.jpg          10004.jpg        exact       None\n",
       "3   10005.jpg     10005.jpg          10005.jpg        exact       None\n",
       "4   10006.jpg     10006.jpg          10006.jpg        exact       None\n",
       "5   10008.jpg     10008.jpg          10008.jpg        exact       None\n",
       "6    1001.jpg      1001.jpg           1001.jpg        exact       None\n",
       "7   10010.jpg     10010.jpg          10010.jpg        exact       None\n",
       "8   10013.jpg     10013.jpg          10013.jpg        exact       None\n",
       "9   10015.jpg     10015.jpg          10015.jpg        exact       None\n",
       "10  10016.jpg     10016.jpg          10016.jpg        exact       None\n",
       "11  10017.jpg     10017.jpg          10017.jpg        exact       None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of manual suggestion cases (first 12):\n",
      "\n",
      "Original CSV rows: 2331; matched now: 2331 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Fixed heuristic-matching cell (ensures match_method/match_info exist before display)\n",
    "from pathlib import Path\n",
    "import unicodedata, re\n",
    "from collections import defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "IMG_ROOT = Path(\"fitzpatrick17k\") / \"images\"\n",
    "print(\"IMG_ROOT:\", IMG_ROOT, \"exists:\", IMG_ROOT.exists())\n",
    "\n",
    "# ensure file_basename present\n",
    "if \"file_basename\" not in df.columns:\n",
    "    df[\"file_basename\"] = df[\"file\"].astype(str).apply(lambda s: str(s).strip().split(\"/\")[-1].split(\"\\\\\")[-1].lower())\n",
    "\n",
    "# build disk maps\n",
    "files = [p for p in IMG_ROOT.rglob(\"*\") if p.is_file()]\n",
    "disk_map = {unicodedata.normalize(\"NFKC\", p.name).lower(): p.relative_to(IMG_ROOT) for p in files}\n",
    "disk_stems_map = defaultdict(list)\n",
    "for p in files:\n",
    "    stem = unicodedata.normalize(\"NFKC\", p.stem).lower()\n",
    "    disk_stems_map[stem].append(p.relative_to(IMG_ROOT))\n",
    "\n",
    "# baseline matched/unmatched\n",
    "matched_mask = df[\"file_basename\"].apply(lambda b: b in disk_map)\n",
    "already_matched = df.loc[matched_mask].copy()\n",
    "unmatched = df.loc[~matched_mask].copy()\n",
    "print(\"Already matched (baseline):\", len(already_matched), \"Unmatched:\", len(unmatched))\n",
    "\n",
    "def extract_number_tokens(s):\n",
    "    return sorted(set(re.findall(r'\\d+', s)), key=lambda x: -len(x))\n",
    "\n",
    "def best_fuzzy_candidate(target, candidates, min_ratio=0.88):\n",
    "    best=None; best_ratio=0.0\n",
    "    for c in candidates:\n",
    "        r = SequenceMatcher(None, target, c).ratio()\n",
    "        if r>best_ratio:\n",
    "            best_ratio=r; best=c\n",
    "    if best_ratio>=min_ratio:\n",
    "        return best, best_ratio\n",
    "    return None, None\n",
    "\n",
    "auto_matches = {}\n",
    "manual_suggestions = {}\n",
    "\n",
    "for idx, row in unmatched.iterrows():\n",
    "    b = row[\"file_basename\"]\n",
    "    stem = Path(b).stem\n",
    "    # 1) stem exact\n",
    "    if stem in disk_stems_map and len(disk_stems_map[stem])==1:\n",
    "        auto_matches[idx] = (str(disk_stems_map[stem][0]), \"stem_exact\", None)\n",
    "        continue\n",
    "    # 2) numeric containment\n",
    "    nums = extract_number_tokens(b)\n",
    "    if nums:\n",
    "        main = nums[0]\n",
    "        candidates = [k for k in disk_map.keys() if main in k]\n",
    "        if len(candidates)==1:\n",
    "            auto_matches[idx] = (str(disk_map[candidates[0]]), \"contains_number\", main)\n",
    "            continue\n",
    "        elif 1 < len(candidates) <= 6:\n",
    "            manual_suggestions[idx] = [str(disk_map[c]) for c in candidates]\n",
    "            continue\n",
    "    # 3) endswith\n",
    "    tail = b\n",
    "    candidates = [k for k in disk_map.keys() if k.endswith(tail)]\n",
    "    if len(candidates)==1:\n",
    "        auto_matches[idx] = (str(disk_map[candidates[0]]), \"endswith\", None)\n",
    "        continue\n",
    "    elif 1 < len(candidates) <= 6:\n",
    "        manual_suggestions[idx] = [str(disk_map[c]) for c in candidates]\n",
    "        continue\n",
    "    # 4) fuzzy basename\n",
    "    cand, ratio = best_fuzzy_candidate(b, disk_map.keys(), min_ratio=0.88)\n",
    "    if cand:\n",
    "        auto_matches[idx] = (str(disk_map[cand]), \"fuzzy\", float(ratio))\n",
    "        continue\n",
    "    # 5) fuzzy stem -> single file\n",
    "    cand, ratio = best_fuzzy_candidate(stem, disk_stems_map.keys(), min_ratio=0.92)\n",
    "    if cand and len(disk_stems_map[cand])==1:\n",
    "        auto_matches[idx] = (str(disk_stems_map[cand][0]), \"fuzzy_stem\", float(ratio))\n",
    "        continue\n",
    "    manual_suggestions.setdefault(idx, [])\n",
    "\n",
    "# Build df2 with resolved_path_auto\n",
    "df2 = df.copy()\n",
    "df2[\"resolved_path_auto\"] = df2[\"file_basename\"].apply(lambda b: str(disk_map[b]) if b in disk_map else None)\n",
    "\n",
    "# Ensure match_method & match_info columns exist\n",
    "if \"match_method\" not in df2.columns: df2[\"match_method\"] = None\n",
    "if \"match_info\"  not in df2.columns: df2[\"match_info\"]  = None\n",
    "\n",
    "# Fill in auto_matches\n",
    "for idx, (rel, method, info) in auto_matches.items():\n",
    "    df2.at[idx, \"resolved_path_auto\"] = rel\n",
    "    df2.at[idx, \"match_method\"] = method\n",
    "    df2.at[idx, \"match_info\"] = info\n",
    "\n",
    "# Mark exact where resolved_path_auto exists and no method set\n",
    "df2[\"match_method\"] = df2[\"match_method\"].fillna(df2[\"resolved_path_auto\"].notna().map(lambda x: \"exact\" if x else None))\n",
    "\n",
    "# Summaries\n",
    "df_matched = df2[df2[\"resolved_path_auto\"].notna()].copy().reset_index(drop=True)\n",
    "df_unmatched = df2[df2[\"resolved_path_auto\"].isna()].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"Auto matches found:\", len(auto_matches))\n",
    "print(\"Manual suggestion cases:\", len([k for k,v in manual_suggestions.items() if v]))\n",
    "print(\"Remaining fully unmatched:\", len(df_unmatched))\n",
    "print(\"Matched by method counts:\\n\", df_matched[\"match_method\"].value_counts(dropna=False))\n",
    "\n",
    "# Safely display only existing columns\n",
    "cols = [c for c in [\"file\",\"file_basename\",\"resolved_path_auto\",\"match_method\",\"match_info\"] if c in df_matched.columns]\n",
    "print(\"\\nExamples of auto matches:\")\n",
    "display(df_matched[cols].head(12))\n",
    "\n",
    "print(\"\\nExamples of manual suggestion cases (first 12):\")\n",
    "man_items = [(idx, manual_suggestions[idx]) for idx in list(manual_suggestions.keys())[:12] if manual_suggestions[idx]]\n",
    "for idx, cand_list in man_items:\n",
    "    print(\"CSV row idx\", idx, \"file\", df.loc[idx,\"file\"], \" -> candidates:\", cand_list[:6])\n",
    "\n",
    "print(f\"\\nOriginal CSV rows: {len(df)}; matched now: {len(df_matched)} ({len(df_matched)/len(df):.1%})\")\n",
    "\n",
    "# leave df2/df_matched/df_unmatched in namespace for review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "951e100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2[df2[\"resolved_path_auto\"].notna()].copy().reset_index(drop=True)\n",
    "df[\"resolved_path\"] = df[\"resolved_path_auto\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061f82d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final df shape: 2331\n",
      "Counts per 3-class label (0=light,1=medium,2=dark):\n",
      "label3\n",
      "0     501\n",
      "1     827\n",
      "2    1003\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resolved_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "phototype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label3",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4f7ae9b8-9206-43d0-a503-8e32587397fd",
       "rows": [
        [
         "0",
         "100.jpg",
         "100.jpg",
         "III",
         "1"
        ],
        [
         "1",
         "1000.jpg",
         "1000.jpg",
         "IV",
         "1"
        ],
        [
         "2",
         "10004.jpg",
         "10004.jpg",
         "V",
         "2"
        ],
        [
         "3",
         "10005.jpg",
         "10005.jpg",
         "V",
         "2"
        ],
        [
         "4",
         "10006.jpg",
         "10006.jpg",
         "VI",
         "2"
        ],
        [
         "5",
         "10008.jpg",
         "10008.jpg",
         "III",
         "1"
        ],
        [
         "6",
         "1001.jpg",
         "1001.jpg",
         "V",
         "2"
        ],
        [
         "7",
         "10010.jpg",
         "10010.jpg",
         "V",
         "2"
        ],
        [
         "8",
         "10013.jpg",
         "10013.jpg",
         "III",
         "1"
        ],
        [
         "9",
         "10015.jpg",
         "10015.jpg",
         "III",
         "1"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>resolved_path</th>\n",
       "      <th>phototype</th>\n",
       "      <th>label3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>100.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>IV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>10005.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>VI</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>10008.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>10013.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>10015.jpg</td>\n",
       "      <td>III</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file resolved_path phototype  label3\n",
       "0    100.jpg       100.jpg       III       1\n",
       "1   1000.jpg      1000.jpg        IV       1\n",
       "2  10004.jpg     10004.jpg         V       2\n",
       "3  10005.jpg     10005.jpg         V       2\n",
       "4  10006.jpg     10006.jpg        VI       2\n",
       "5  10008.jpg     10008.jpg       III       1\n",
       "6   1001.jpg      1001.jpg         V       2\n",
       "7  10010.jpg     10010.jpg         V       2\n",
       "8  10013.jpg     10013.jpg       III       1\n",
       "9  10015.jpg     10015.jpg       III       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accept auto-matched rows and finalize resolved_path and label3\n",
    "# (Be sure df2 exists in namespace from the previous step)\n",
    "assert \"df2\" in globals(), \"df2 not found — re-run the matching step\"\n",
    "\n",
    "# keep only matched rows\n",
    "df = df2[df2[\"resolved_path_auto\"].notna()].copy().reset_index(drop=True)\n",
    "df[\"resolved_path\"] = df[\"resolved_path_auto\"]  # set final path\n",
    "# If you already created label3 earlier, keep it; otherwise create from phototype\n",
    "if \"label3\" not in df.columns:\n",
    "    import re\n",
    "    def parse_phototype(s):\n",
    "        if pd.isna(s): return None\n",
    "        s = str(s).upper()\n",
    "        m = re.search(r'\\b(I{1,3}|IV|V|VI|[1-6])\\b', s)\n",
    "        if not m: return None\n",
    "        token = m.group(1)\n",
    "        rm = {\"I\":1,\"II\":2,\"III\":3,\"IV\":4,\"V\":5,\"VI\":6}\n",
    "        if token in rm: return rm[token]\n",
    "        try: return int(token)\n",
    "        except: return None\n",
    "    df[\"phototype_num\"] = df[\"phototype\"].apply(parse_phototype)\n",
    "    def to_label3(x):\n",
    "        if pd.isna(x): return None\n",
    "        x=int(x)\n",
    "        if x<=2: return 0\n",
    "        if x<=4: return 1\n",
    "        return 2\n",
    "    df[\"label3\"] = df[\"phototype_num\"].apply(lambda x: to_label3(x) if pd.notna(x) else None)\n",
    "\n",
    "# final sanity\n",
    "print(\"Final df shape:\", len(df))\n",
    "print(\"Counts per 3-class label (0=light,1=medium,2=dark):\")\n",
    "print(df[\"label3\"].value_counts().sort_index())\n",
    "# show sample rows\n",
    "display(df[[\"file\",\"resolved_path\",\"phototype\",\"label3\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae45017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 1863 val len: 468\n",
      "train class counts: Counter({2: 802, 1: 661, 0: 400})\n",
      "val class counts: Counter({2: 201, 1: 166, 0: 101})\n"
     ]
    }
   ],
   "source": [
    "# Stratified split 80/20 (recompute from current df)\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "indices_by_class = defaultdict(list)\n",
    "for idx, lbl in enumerate(df[\"label3\"].astype(int).values):\n",
    "    indices_by_class[int(lbl)].append(idx)\n",
    "\n",
    "train_idx, val_idx = [], []\n",
    "frac_train = 0.8\n",
    "for lbl, idxs in indices_by_class.items():\n",
    "    idxs = idxs.copy()\n",
    "    np.random.shuffle(idxs)\n",
    "    split = int(len(idxs) * frac_train)\n",
    "    train_idx += idxs[:split]\n",
    "    val_idx += idxs[split:]\n",
    "\n",
    "train_idx = sorted(set(train_idx))\n",
    "val_idx   = sorted(set(val_idx))\n",
    "print(\"train len:\", len(train_idx), \"val len:\", len(val_idx))\n",
    "print(\"train class counts:\", Counter(df.loc[train_idx,\"label3\"]))\n",
    "print(\"val class counts:\", Counter(df.loc[val_idx,\"label3\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa9d37d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds not found — creating Melanin3Dataset from train_df (requires train_idx/train_df exist).\n",
      "Created train_ds length: 1863\n",
      "\n",
      "Timing a few batches with num_workers=0:\n",
      " batch  0: imgs (8, 3, 224, 224), labels min/max 1/2, time 1.859s\n",
      " batch  1: imgs (8, 3, 224, 224), labels min/max 0/2, time 0.016s\n",
      " batch  2: imgs (8, 3, 224, 224), labels min/max 0/2, time 0.016s\n",
      " batch  3: imgs (8, 3, 224, 224), labels min/max 1/2, time 0.010s\n",
      " batch  4: imgs (8, 3, 224, 224), labels min/max 0/2, time 0.009s\n",
      " batch  5: imgs (8, 3, 224, 224), labels min/max 0/2, time 0.004s\n",
      "\n",
      "If these batch times are small, use num_workers=0 for notebook training to avoid long worker spawn delays.\n",
      "To rebuild your main train_loader quickly, run the cell below (it sets num_workers=0):\n",
      "\n",
      "# Rebuild example (paste and run):\n",
      "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
      "train_loader = DataLoader(train_ds, batch_size=64, sampler=sampler, num_workers=0, pin_memory=True if torch.cuda.is_available() else False)\n",
      "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=0, pin_memory=True if torch.cuda.is_available() else False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix & diagnostic: make sure we have a Dataset, then time a few batches with num_workers=0\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "# adapt these if your names differ\n",
    "IMG_ROOT = Path(\"fitzpatrick17k\") / \"images\"\n",
    "IMG_SIZE = 224\n",
    "BATCH = 8\n",
    "\n",
    "# 1) If train_ds isn't defined, create a minimal Dataset wrapper for train_df\n",
    "if 'train_ds' not in globals():\n",
    "    print(\"train_ds not found — creating Melanin3Dataset from train_df (requires train_idx/train_df exist).\")\n",
    "    # sanity checks\n",
    "    assert 'train_idx' in globals() and 'df' in globals(), \"train_idx or df missing — run the split cells first.\"\n",
    "    train_df = df.loc[train_idx].reset_index(drop=True)\n",
    "    # small, safe transform for timing (no heavy color jitter)\n",
    "    tf = T.Compose([T.Resize((IMG_SIZE, IMG_SIZE)), T.ToTensor()])\n",
    "    class QuickDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, df_subset, img_root, path_col='resolved_path', label_col='label3', tf=None):\n",
    "            self.df = df_subset.reset_index(drop=True)\n",
    "            self.img_root = Path(img_root)\n",
    "            self.path_col = path_col\n",
    "            self.label_col = label_col\n",
    "            self.tf = tf\n",
    "        def __len__(self): return len(self.df)\n",
    "        def __getitem__(self, idx):\n",
    "            row = self.df.iloc[idx]\n",
    "            p = self.img_root / row[self.path_col]\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "            if self.tf: img = self.tf(img)\n",
    "            lbl = int(row[self.label_col])\n",
    "            return img, torch.tensor(lbl, dtype=torch.long)\n",
    "    train_ds = QuickDataset(train_df, IMG_ROOT, tf=tf)\n",
    "    print(\"Created train_ds length:\", len(train_ds))\n",
    "else:\n",
    "    print(\"Using existing train_ds (len={})\".format(len(train_ds)))\n",
    "\n",
    "# 2) Create a single-process test loader and time a few batches\n",
    "test_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "print(\"\\nTiming a few batches with num_workers=0:\")\n",
    "t0 = time.time()\n",
    "for i, (imgs, labs) in enumerate(test_loader):\n",
    "    t1 = time.time()\n",
    "    print(f\" batch {i:2d}: imgs {tuple(imgs.shape)}, labels min/max {labs.min().item()}/{labs.max().item()}, time {(t1-t0):.3f}s\")\n",
    "    t0 = time.time()\n",
    "    if i >= 5:\n",
    "        break\n",
    "\n",
    "# 3) If this is fast (<~0.5–1s per small batch) use num_workers=0 for interactive training:\n",
    "print(\"\\nIf these batch times are small, use num_workers=0 for notebook training to avoid long worker spawn delays.\")\n",
    "print(\"To rebuild your main train_loader quickly, run the cell below (it sets num_workers=0):\")\n",
    "\n",
    "# quick snippet to rebuild your main loaders safely\n",
    "print(\"\"\"\n",
    "# Rebuild example (paste and run):\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "train_loader = DataLoader(train_ds, batch_size=64, sampler=sampler, num_workers=0, pin_memory=True if torch.cuda.is_available() else False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=0, pin_memory=True if torch.cuda.is_available() else False)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e67006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "=== Epoch 1/6 ===\n",
      " batch    1 | batch_time 0.790s | avg_loss 1.3569 | avg_acc 0.2656 | lr 0.0003 | grad_norm 9.6298\n",
      " batch   10 | batch_time 0.594s | avg_loss 1.0436 | avg_acc 0.4328 | lr 0.0003 | grad_norm 5.7499\n",
      " batch   20 | batch_time 0.599s | avg_loss 0.9592 | avg_acc 0.4789 | lr 0.0003 | grad_norm 4.3118\n",
      " batch   30 | batch_time 0.107s | avg_loss 0.8959 | avg_acc 0.5228 | lr 0.0003 | grad_norm 6.3320\n",
      "Epoch 1 train_loss 0.8959 train_acc 0.5228 time 18.8s mean_batch 0.556s\n",
      "Epoch 1 VALID  val_loss 1.6539 val_acc 0.2735\n",
      " Confusion matrix:\n",
      " [[ 75   0  26]\n",
      " [110   0  56]\n",
      " [148   0  53]]\n",
      " Per-class recall: [0.74257426 0.         0.26368159]\n",
      " Saved new best model -> best_resnet18_3class_verbose.pth\n",
      "\n",
      "=== Epoch 2/6 ===\n",
      " batch    1 | batch_time 0.489s | avg_loss 0.6051 | avg_acc 0.7344 | lr 0.0003 | grad_norm 6.0874\n",
      " batch   10 | batch_time 0.582s | avg_loss 0.6293 | avg_acc 0.7172 | lr 0.0003 | grad_norm 5.0936\n",
      " batch   20 | batch_time 0.575s | avg_loss 0.5647 | avg_acc 0.7461 | lr 0.0003 | grad_norm 6.7858\n",
      " batch   30 | batch_time 0.076s | avg_loss 0.5325 | avg_acc 0.7665 | lr 0.0003 | grad_norm 4.0386\n",
      "Epoch 2 train_loss 0.5325 train_acc 0.7665 time 18.2s mean_batch 0.542s\n",
      "Epoch 2 VALID  val_loss 1.6961 val_acc 0.4295\n",
      " Confusion matrix:\n",
      " [[  3   0  98]\n",
      " [  2   0 164]\n",
      " [  3   0 198]]\n",
      " Per-class recall: [0.02970297 0.         0.98507463]\n",
      " Saved new best model -> best_resnet18_3class_verbose.pth\n",
      "\n",
      "=== Epoch 3/6 ===\n",
      " batch    1 | batch_time 0.587s | avg_loss 0.5761 | avg_acc 0.6875 | lr 0.0003 | grad_norm 6.7178\n",
      " batch   10 | batch_time 0.553s | avg_loss 0.4210 | avg_acc 0.8109 | lr 0.0003 | grad_norm 4.0161\n",
      " batch   20 | batch_time 0.562s | avg_loss 0.3578 | avg_acc 0.8500 | lr 0.0003 | grad_norm 5.1633\n",
      " batch   30 | batch_time 0.073s | avg_loss 0.3273 | avg_acc 0.8669 | lr 0.0003 | grad_norm 22.4458\n",
      "Epoch 3 train_loss 0.3273 train_acc 0.8669 time 17.6s mean_batch 0.527s\n",
      "Epoch 3 VALID  val_loss 1.7294 val_acc 0.4188\n",
      " Confusion matrix:\n",
      " [[  1   1  99]\n",
      " [  6   3 157]\n",
      " [  7   2 192]]\n",
      " Per-class recall: [0.00990099 0.01807229 0.95522388]\n",
      "\n",
      "=== Epoch 4/6 ===\n",
      " batch    1 | batch_time 0.580s | avg_loss 0.1108 | avg_acc 0.9844 | lr 0.0003 | grad_norm 2.5691\n",
      " batch   10 | batch_time 0.571s | avg_loss 0.2138 | avg_acc 0.9203 | lr 0.0003 | grad_norm 2.9436\n",
      " batch   20 | batch_time 0.570s | avg_loss 0.2362 | avg_acc 0.9148 | lr 0.0003 | grad_norm 5.6188\n",
      " batch   30 | batch_time 0.075s | avg_loss 0.2225 | avg_acc 0.9179 | lr 0.0003 | grad_norm 10.0418\n",
      "Epoch 4 train_loss 0.2225 train_acc 0.9179 time 17.5s mean_batch 0.525s\n",
      "Epoch 4 VALID  val_loss 1.7885 val_acc 0.3761\n",
      " Confusion matrix:\n",
      " [[ 13   0  88]\n",
      " [ 18   3 145]\n",
      " [ 34   7 160]]\n",
      " Per-class recall: [0.12871287 0.01807229 0.7960199 ]\n",
      "\n",
      "=== Epoch 5/6 ===\n",
      " batch    1 | batch_time 0.589s | avg_loss 0.1462 | avg_acc 0.9375 | lr 0.0003 | grad_norm 3.5912\n",
      " batch   10 | batch_time 0.560s | avg_loss 0.1676 | avg_acc 0.9437 | lr 0.0003 | grad_norm 4.2988\n",
      " batch   20 | batch_time 0.467s | avg_loss 0.1726 | avg_acc 0.9422 | lr 0.0003 | grad_norm 5.9769\n",
      " batch   30 | batch_time 0.071s | avg_loss 0.1542 | avg_acc 0.9474 | lr 0.0003 | grad_norm 23.7059\n",
      "Epoch 5 train_loss 0.1542 train_acc 0.9474 time 17.7s mean_batch 0.529s\n",
      "Epoch 5 VALID  val_loss 4.9070 val_acc 0.4295\n",
      " Confusion matrix:\n",
      " [[  0   0 101]\n",
      " [  0   0 166]\n",
      " [  0   0 201]]\n",
      " Per-class recall: [0. 0. 1.]\n",
      "\n",
      "=== Epoch 6/6 ===\n",
      " batch    1 | batch_time 0.600s | avg_loss 0.0763 | avg_acc 0.9688 | lr 0.00015 | grad_norm 2.4187\n",
      " batch   10 | batch_time 0.582s | avg_loss 0.1532 | avg_acc 0.9422 | lr 0.00015 | grad_norm 3.0857\n",
      " batch   20 | batch_time 0.566s | avg_loss 0.1339 | avg_acc 0.9492 | lr 0.00015 | grad_norm 4.7789\n",
      " batch   30 | batch_time 0.070s | avg_loss 0.1143 | avg_acc 0.9587 | lr 0.00015 | grad_norm 3.8877\n",
      "Epoch 6 train_loss 0.1143 train_acc 0.9587 time 17.7s mean_batch 0.534s\n",
      "Epoch 6 VALID  val_loss 4.1757 val_acc 0.4316\n",
      " Confusion matrix:\n",
      " [[  2   0  99]\n",
      " [  0   0 166]\n",
      " [  1   0 200]]\n",
      " Per-class recall: [0.01980198 0.         0.99502488]\n",
      " Saved new best model -> best_resnet18_3class_verbose.pth\n",
      "\n",
      "Training finished. Best val acc: 0.43162393162393164\n"
     ]
    }
   ],
   "source": [
    "# Verbose training loop (drop-in). Paste & run this cell.\n",
    "import time, math, torch, numpy as np\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Safety checks\n",
    "assert 'train_loader' in globals() and 'val_loader' in globals(), \"train_loader / val_loader missing.\"\n",
    "assert 'model' in globals(), \"model missing.\"\n",
    "\n",
    "# Ensure model on device and in train mode\n",
    "model = model.to(device)\n",
    "for p in model.parameters(): \n",
    "    p.requires_grad = True\n",
    "model.train()\n",
    "\n",
    "# Optimizer + scheduler (recreate to be sure we have fresh state)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "# Use weighted loss if you computed class_weights earlier\n",
    "if 'class_weights' in globals():\n",
    "    loss_weight = torch.tensor([class_weights.get(i,1.0) for i in range(3)], dtype=torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 6\n",
    "LOG_EVERY = 10   # print every N batches\n",
    "best_val_acc = 0.0\n",
    "save_path = \"best_resnet18_3class_verbose.pth\"\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    batch_times = []\n",
    "    print(f\"\\n=== Epoch {epoch}/{EPOCHS} ===\")\n",
    "    for b_idx, (imgs, labels) in enumerate(train_loader, start=1):\n",
    "        t0 = time.time()\n",
    "        imgs = imgs.to(device); labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        # gradient norm (useful)\n",
    "        total_grad_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                total_grad_norm += float(p.grad.detach().norm().item()**2)\n",
    "        total_grad_norm = math.sqrt(total_grad_norm) if total_grad_norm>0 else 0.0\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # stats\n",
    "        preds = out.argmax(1)\n",
    "        batch_correct = int((preds == labels).sum().item())\n",
    "        running_correct += batch_correct\n",
    "        running_total += labels.size(0)\n",
    "        running_loss += float(loss.item()) * labels.size(0)\n",
    "\n",
    "        bt = time.time()-t0\n",
    "        batch_times.append(bt)\n",
    "\n",
    "        if b_idx % LOG_EVERY == 0 or b_idx == 1:\n",
    "            avg_loss = running_loss / running_total\n",
    "            avg_acc = running_correct / running_total\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\" batch {b_idx:4d} | batch_time {bt:.3f}s | avg_loss {avg_loss:.4f} | avg_acc {avg_acc:.4f} | lr {lr:.6g} | grad_norm {total_grad_norm:.4f}\")\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc  = running_correct / running_total\n",
    "    print(f\"Epoch {epoch} train_loss {train_loss:.4f} train_acc {train_acc:.4f} time {epoch_time:.1f}s mean_batch {np.mean(batch_times):.3f}s\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0; val_total=0; val_correct=0\n",
    "    y_true=[]; y_pred=[]\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device); labels = labels.to(device)\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "            preds = out.argmax(1)\n",
    "            val_loss += float(loss.item()) * imgs.size(0)\n",
    "            val_total += imgs.size(0)\n",
    "            val_correct += int((preds==labels).sum().item())\n",
    "            y_true.extend(labels.cpu().numpy().tolist()); y_pred.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    val_loss = val_loss / max(1, val_total)\n",
    "    val_acc  = val_correct / max(1, val_total)\n",
    "    print(f\"Epoch {epoch} VALID  val_loss {val_loss:.4f} val_acc {val_acc:.4f}\")\n",
    "\n",
    "    # confusion matrix quick\n",
    "    num_c = 3\n",
    "    cm = np.zeros((num_c, num_c), dtype=int)\n",
    "    for t,p in zip(y_true, y_pred):\n",
    "        cm[int(t), int(p)] += 1\n",
    "    print(\" Confusion matrix:\\n\", cm)\n",
    "    per_class_recall = np.diag(cm) / np.clip(cm.sum(axis=1), 1, None)\n",
    "    print(\" Per-class recall:\", per_class_recall)\n",
    "\n",
    "    # checkpoint\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\" Saved new best model ->\", save_path)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\nTraining finished. Best val acc:\", best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4ee2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[  2   0  99]\n",
      " [  0   0 166]\n",
      " [  1   0 200]]\n",
      "Per-class counts: [101, 166, 201]\n",
      "Recall: [0.019801980198019802, 0.0, 0.9950248756218906]\n",
      "Precision: [0.6666666666666666, 0.0, 0.43010752688172044]\n",
      "F1: [0.038461538461538464, 0.0, 0.6006006006006006]\n"
     ]
    }
   ],
   "source": [
    "# Cell: confusion and per-class metrics (if y_true, y_pred exist)\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "assert 'y_true' in globals() and 'y_pred' in globals(), \"Run validation to produce y_true,y_pred first.\"\n",
    "\n",
    "num_c = 3\n",
    "cm = np.zeros((num_c, num_c), dtype=int)\n",
    "for t,p in zip(y_true, y_pred):\n",
    "    cm[int(t), int(p)] += 1\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "recall = np.diag(cm) / np.clip(cm.sum(axis=1), 1, None)\n",
    "precision = np.diag(cm) / np.clip(cm.sum(axis=0), 1, None)\n",
    "f1 = 2 * precision * recall / np.clip(precision + recall, 1e-8, None)\n",
    "print(\"Per-class counts:\", cm.sum(axis=1).tolist())\n",
    "print(\"Recall:\", recall.tolist())\n",
    "print(\"Precision:\", precision.tolist())\n",
    "print(\"F1:\", f1.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e781d3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 linear feat model -> train_acc 0.389 val_acc 0.440\n",
      "Epoch 2 linear feat model -> train_acc 0.425 val_acc 0.434\n",
      "Epoch 3 linear feat model -> train_acc 0.428 val_acc 0.429\n",
      "Epoch 4 linear feat model -> train_acc 0.430 val_acc 0.429\n",
      "Epoch 5 linear feat model -> train_acc 0.430 val_acc 0.429\n",
      "Epoch 6 linear feat model -> train_acc 0.430 val_acc 0.429\n",
      "Epoch 7 linear feat model -> train_acc 0.430 val_acc 0.429\n",
      "Epoch 8 linear feat model -> train_acc 0.429 val_acc 0.429\n",
      "Epoch 9 linear feat model -> train_acc 0.430 val_acc 0.429\n",
      "Epoch 10 linear feat model -> train_acc 0.430 val_acc 0.429\n"
     ]
    }
   ],
   "source": [
    "# Cell: compute simple color features and train a small linear classifier\n",
    "import torch, torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np, math\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Dataset that returns small handcrafted features\n",
    "class ColorFeatDataset(Dataset):\n",
    "    def __init__(self, df_subset, img_root, path_col='resolved_path', label_col='label3', img_size=128):\n",
    "        self.df = df_subset.reset_index(drop=True)\n",
    "        self.root = img_root\n",
    "        self.path_col = path_col\n",
    "        self.label_col = label_col\n",
    "        self.tf = T.Compose([T.Resize((img_size,img_size))])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        p = self.root / row[self.path_col]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        img = self.tf(img)\n",
    "        arr = np.array(img).astype(np.float32)/255.0  # H,W,3\n",
    "        # mean RGB\n",
    "        mean_rgb = arr.mean(axis=(0,1))  # 3\n",
    "        # HSV saturation mean\n",
    "        from colorsys import rgb_to_hsv\n",
    "        h_avg = []; s_avg = []\n",
    "        # compute mean saturation by sampling a grid (faster than full per-pixel loop)\n",
    "        small = arr.reshape(-1,3)[::max(1, arr.size//5000)]\n",
    "        sats = [rgb_to_hsv(*tuple(px))[1] for px in small]\n",
    "        sat_mean = float(np.mean(sats))\n",
    "        # mean Y from YCbCr (brightness)\n",
    "        img_ycbcr = Image.fromarray((arr*255).astype(np.uint8)).convert(\"YCbCr\")\n",
    "        Y, Cb, Cr = np.array(img_ycbcr).astype(np.float32).mean(axis=(0,1))\n",
    "        feats = np.concatenate([mean_rgb, [sat_mean, Y/255.0]])\n",
    "        label = int(row[self.label_col])\n",
    "        return torch.tensor(feats, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# build datasets using current train_df/val_df from your notebook\n",
    "assert 'train_df' in globals() and 'val_df' in globals()\n",
    "feat_train = ColorFeatDataset(train_df, IMG_ROOT)\n",
    "feat_val   = ColorFeatDataset(val_df,   IMG_ROOT)\n",
    "train_loader_f = DataLoader(feat_train, batch_size=64, shuffle=True, num_workers=0)\n",
    "val_loader_f   = DataLoader(feat_val,   batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "# a tiny linear classifier (input dim = 5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_f = nn.Sequential(nn.Linear(5, 32), nn.ReLU(), nn.Linear(32, 3)).to(device)\n",
    "opt = torch.optim.AdamW(model_f.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "# train a few epochs\n",
    "for epoch in range(10):\n",
    "    model_f.train()\n",
    "    tot_loss=0; tot=0; corr=0\n",
    "    for X, y in train_loader_f:\n",
    "        X=X.to(device); y=y.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model_f(X)\n",
    "        loss = crit(out,y)\n",
    "        loss.backward(); opt.step()\n",
    "        tot_loss += loss.item()*X.size(0)\n",
    "        corr += (out.argmax(1)==y).sum().item(); tot+=X.size(0)\n",
    "    train_acc = corr/tot\n",
    "    # val\n",
    "    model_f.eval()\n",
    "    corr=0; tot=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in val_loader_f:\n",
    "            X=X.to(device); y=y.to(device)\n",
    "            out = model_f(X)\n",
    "            corr += (out.argmax(1)==y).sum().item(); tot+=X.size(0)\n",
    "    val_acc = corr/tot\n",
    "    print(f\"Epoch {epoch+1} linear feat model -> train_acc {train_acc:.3f} val_acc {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d19bae28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n",
      "Epoch 2 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n",
      "Epoch 3 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n",
      "Epoch 4 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n",
      "Epoch 5 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n",
      "Epoch 6 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n",
      "Epoch 7 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n",
      "Epoch 8 train_acc 0.43048845947396674 val_acc 0.42948717948717946\n"
     ]
    }
   ],
   "source": [
    "# Cell: compute simple HSV skin mask and per-image masked mean Y, then test linear classifier\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def simple_skin_mask_rgb(arr_rgb):\n",
    "    # arr_rgb in 0..1\n",
    "    import colorsys\n",
    "    hws = arr_rgb.reshape(-1,3)\n",
    "    mask = []\n",
    "    for r,g,b in hws:\n",
    "        h,s,v = colorsys.rgb_to_hsv(r,g,b)\n",
    "        # heuristic thresholds (tunable); keep moderately saturated warm colors\n",
    "        if s > 0.1 and v > 0.15 and 0.0 <= h <= 0.7:\n",
    "            mask.append(1)\n",
    "        else:\n",
    "            mask.append(0)\n",
    "    m = np.array(mask, dtype=np.uint8).reshape(arr_rgb.shape[0], arr_rgb.shape[1])\n",
    "    return m\n",
    "\n",
    "class MaskedFeatDataset(Dataset):\n",
    "    def __init__(self, df_subset, img_root, img_size=128):\n",
    "        self.df = df_subset.reset_index(drop=True)\n",
    "        self.root = img_root\n",
    "        self.img_size = img_size\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        p = self.root / row['resolved_path']\n",
    "        img = Image.open(p).convert('RGB').resize((self.img_size, self.img_size))\n",
    "        arr = np.array(img).astype(np.float32)/255.0\n",
    "        mask = simple_skin_mask_rgb(arr)\n",
    "        if mask.sum() == 0:\n",
    "            # fallback: whole image\n",
    "            mask = np.ones((self.img_size, self.img_size), dtype=np.uint8)\n",
    "        # compute masked mean RGB and mean brightness (Y)\n",
    "        masked = arr * mask[:,:,None]\n",
    "        mean_rgb = masked.sum(axis=(0,1)) / (mask.sum()+1e-6)\n",
    "        img_ycbcr = Image.fromarray((arr*255).astype(np.uint8)).convert(\"YCbCr\")\n",
    "        Y = np.array(img_ycbcr)[:,:,0]\n",
    "        mean_Y_masked = (Y * mask).sum() / (mask.sum()+1e-6) / 255.0\n",
    "        feats = np.concatenate([mean_rgb, [mean_Y_masked]])\n",
    "        label = int(row['label3'])\n",
    "        return torch.tensor(feats, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# build and test the same linear classifier routine as before but using MaskedFeatDataset\n",
    "masked_train = MaskedFeatDataset(train_df, IMG_ROOT)\n",
    "masked_val   = MaskedFeatDataset(val_df, IMG_ROOT)\n",
    "train_loader_m = DataLoader(masked_train, batch_size=64, shuffle=True, num_workers=0)\n",
    "val_loader_m   = DataLoader(masked_val,   batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "# tiny model\n",
    "model_m = nn.Sequential(nn.Linear(4, 32), nn.ReLU(), nn.Linear(32,3)).to(device)\n",
    "opt_m = torch.optim.AdamW(model_m.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "for epoch in range(8):\n",
    "    model_m.train()\n",
    "    tot=0; corr=0\n",
    "    for X,y in train_loader_m:\n",
    "        X=X.to(device); y=y.to(device)\n",
    "        opt_m.zero_grad()\n",
    "        out = model_m(X)\n",
    "        loss = crit(out,y)\n",
    "        loss.backward(); opt_m.step()\n",
    "        corr += (out.argmax(1)==y).sum().item(); tot+=X.size(0)\n",
    "    model_m.eval()\n",
    "    corr_v=0; tot_v=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in val_loader_m:\n",
    "            X=X.to(device); y=y.to(device)\n",
    "            corr_v += (model_m(X).argmax(1)==y).sum().item(); tot_v+=X.size(0)\n",
    "    print(\"Epoch\", epoch+1, \"train_acc\", corr/tot, \"val_acc\", corr_v/tot_v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
